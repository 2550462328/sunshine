#### 1. 业务架构

![img](http://pcc.huitogo.club/9380d3e440d3ed4cbe9623f48595db19)



#### 2. 架构设计

![img](http://pcc.huitogo.club/966a46bce84632a6ca1cdc5b4d6e63c8)



##### 2.1 限流

- 速率限流


```
http {  
 #每秒流入1000请求
limit_req_zone $uri zone=api_read:150m rate=1000r/s;  
… 

location/v1/pb/twoCode/upload
{
  limit_req zone=api_read burst=600 nodelay;
  proxy_pass http://172.31.185.162:18070/v1/pb/twoCode/upload;
}
```



使用的令牌桶算法

![img](http://pcc.huitogo.club/2a5b144a64ca902f25430ab4cdc8a006)



1. 系统以固定速率产生令牌，并且缓存到令牌桶里。

2. 当令牌桶满时，再来的令牌会被丢弃。

3. 传输报文时，根据报文的大小消费对应数量的令牌。

4. 当令牌不足时，不能够传输报文。




- 并发限流


```
http {  
limit_conn_zone $binary_remote_addrzone=perip:10m; 
limit_conn_zone $server_namezone=perserver:10m;
… 

location/v1/pb/twoCode/upload
{
  limit_conn perip 20;
 limit_conn perserver 100;
 }
```



1. limit_conn perip 20 : 对应的key是 $binary_remote_addr，表示限制单个IP同时最多能的连接。

2. limit_conn perserver 100 : 对应的key是 $server_name，表示虚拟主机(server) 同时能处理并发连接的总数。只有当 request header 被后端server处理后，这个连接才进行计数。




##### 2.2 异步

![img](http://pcc.huitogo.club/4966ed0f611c53f9ca48872f8cff45e2)



##### 2.3 图片存储

**Minio存储**



分布式存储采用去中心无共享架构；每一个节点都是对等的，从而在性能上，不会存在单点瓶颈，也不会有单点故障。

部署情况，3台物理服务，512G内存，25T SSD硬盘;

保留86个桶，测试 tps 写入行程卡图片1500Tps以上,每个节点600Mbps流量

![img](http://pcc.huitogo.club/60f78276f1ffa4ef8aab81c2928c2734)



MinIO 符合一切原生云计算的架构和构建过程，并且包含最新的云计算的全新的技术和概念。 其中包括支持Kubernetes 、微服和多租户的的容器技术。使对象存储对于 Kubernetes更加友好



##### 2.4 资源弹性配置

**OCR识别**



需求：每天ocr识别230万行程卡图片，峰值待识别图片并发600，项目初期根据ocr识别性能，需要40张GPU卡；虽然ocr进行异步识别，也需要保证家长打卡后能够及时查看识别结果。

方案：考虑使用的集中情况，项目初期打卡集中在早上7点左右，无法常态提供对应识别资源；借助飞云平台的弹性能力，进行OCR资源弹性配置，常住200路并发，峰值弹性500路并发，保证用户使用体验，后来打卡业务调整弹性配置也进行了调整

优化后，飞云平台单张GPU卡最大支持20路并发



##### 2.5 多网络高并发访问

需求：每天170万用户通过不同的网络（包括联通、移动、电信等）访问系统，包括上传行程卡图片，需要考虑跨网段高效访问

方案：系统业务应用部署在移动政务云，基于历史情况，为避免不同网段用户跨网段访问系统，卡顿缓慢的风险，增加CDN加速，保证访问流畅。 图片上传宽带的压力更大，考虑讯飞云三网出口，将图片上传业务独立部署讯飞云，保证图片上传业务需求。

![img](http://pcc.huitogo.club/6973f9cd30ad10c8884376583dd725bc)



##### 2.6 混沌测试

验证系统的稳定性，面对异常时的高可用，故引入混沌实验。

![img](http://pcc.huitogo.club/6b16f24710f9059e019ea700ed5818b9)



按照从爆破半径小到大，依次模拟第三方方故障->中间件层>业务服务->基础服务->容器层->操作系统层->系统层。



#### 3. 生产问题分享

##### 3.1 图片存储服务性能瓶颈

现象：推广初期，早高峰期出现大量OCR识别延迟，导致家长反复打卡

分析：由于图片存储IO（stata盘）性能不足，获取图片大量超时，导致行程卡无法及时识别延迟。

处理：物理服务器硬盘SSD，解决性能问题；界面提示信息优化，避免用户重复打卡的情况。

总结：更换SSD硬盘服务器后，保存图片TPS 1500+，同步下载图片TPS 1200+，较之前普通磁盘服务器部署服务TPS 500+性能显著增强



##### 3.2 服务防火墙问题

现象：线上环境压测，500并发线程压测，第三方接口出现间歇性返回内容乱码情况，研发环境压测正常

处理过程：怀疑程序高并发、操作系统编码问题，进行优化验证，研发环境测试没有问题，上线后反复出现；最后定位到防火墙限制问题，公司测试环境出口地址添加过白名单，所有没有乱码的情况，线上环境出口地址添加白名单后解决

总结：遇到问题冷静分析，大胆猜测，线上的很多问题都不是程序问题



##### 3.3 调用CDN接口问题

现象：高峰时期出现大量用户白屏的情况

分析：缓存失效，高峰时段大量请求外部接口，外部接口链路异常，导致服务线程阻塞住，使其他接口也无法正常使用；

外部接口异常原因，接口走CDN，代理服务器会缓存CDN分配ip地址，分配的ip地址不能保证持续可用，失效后导致接口请求失败

![img](http://pcc.huitogo.club/0e11615d07f6f020ef7313fc118310c8)



处理：代理安康码的nginx做了dns正向解析映射增强机制，避免dns缓存时间太长无法正常解析到可用ip。



##### 3.4 兼容性白屏问题

现象：系统升级后，部分用户反馈，进入健康打卡页面白屏 分析：前端的加密模块部分机型存在兼容问题，通过阿里云购买部分模拟机型验证，实际机型过多，修复后无法确认问题是否存在，协调公共卫生技术管理办公室，**实现前端监控白屏异常技术方案，完善前端日志埋点**。

![img](http://pcc.huitogo.club/bf7e2b35b6ae24dc3a1d09f90ef52100)



处理：前端收集异常信息--》后端nginx通过OpenResty 伪装成 gif 图片的脚本，提供log.gif接口 ，接收日志数据，规范格式后打印到日志文件--》日志采集后，在日志监控平台查询



##### 3.5 Nacos降级问题

现象：健康打卡页面无法访问，监控发现健康校园服务节点发生迁移

分析：政务云宿主机异常，服务节点发生迁移后仍无法使用;在nacos2.0.3版本默认开启双写，只要nacos集群其中一个节点挂掉，剩余节点如果不将这个节点从地址列表中移除，只要重启便会出现服务降级，导致nacos新的服务无法注册。

处理：关闭nacos双写，避免组件异常出现服务降级（readyToUpgrade: false）导致注册服务不可用。

总结：在2.0.3版本默认开启双写，只要nacos集群其中一个节点挂掉，剩余节点如果不将这个节点从地址列表中移除，只要重启便会出现服务降级；另外在并发部署的情况下，也有可能出现服务降级。 关闭双写会关闭运行中服务降级的入口，所以2.x服务运行稳定后一定要关闭双写，我们的服务之所以会降级也是因为运行后未关闭双写。



##### 3.6 操作系统端口问题

现象：生产压力测试，发现TPS存在周期性骤降情况；TPS600+ 存在0.14%的服务报错问题

分析：操作系统内核版本升级，tcp_tw_recycle参数废弃，nginx反向代理minio服务产生大量time_wait状态链接无法快速回收，需要等待超时才能再次使用，所以产生周期性波动，反向代理增加长连接配置，调整后，通过生产压力机器100线程测试接口，无周期性报错情况

总结：linux内核通过net.ipv4.tcp_tw_reuse参数控制是否开启time_awit状态复用，linux默认开启的一个tcp时间戳策略net.ipv4.tcp_timestamps = 1



客户端因为有端口65535问题，TIME_OUT过多直接影响处理能力

tcp_tw_recycle这个参数，4.x内核版本之后这个参数已经被废弃了

但如果是NAT的环境，你很难保障后端所有的机器的时钟是同步的，那么就会出现部分数据包被服务端拒绝的情况。所以这个参数请谨慎使用，不建议开启！！！

tw_reuse，tw_recycle 必须在客户端和服务端timestamps 开启时才管用（默认打开）

-tw_reuse 只对客户端起作用，开启后客户端在1s内回收

-tw_recycle 对客户端和服务器同时起作用



##### 3.7 Nginx负载问题

现象：行程卡图片上传失败，退出后进入打卡页面白屏

分析：通过监控发现，大量请求线程运行时间过长，tomcat线程数（默认200）占满，无法接收新的请求;进一步排查发现，图片上传接口中的鉴权接口耗时很长，大量超时情况；

![img](http://pcc.huitogo.club/7351bf1ed5f3b856da01cf668dea702b)



处理：通过CDN负载，将请求分散到4台nginx上，增加后台服务和网关的节点和线程数，提高程序的处理能力

![img](http://pcc.huitogo.club/d7e3c021a1f05485ebcc6d78fcdc0753)



总结：该问题最初发现存在redis主从切换情况，从该角度也进行了较长时间的分析，为了排查组件对服务的影响，开展混沌测试



##### 3.8 TCP协议TIME_WAIT状态

tw产生场景

TCP 连接建立后，「主动关闭连接」的一端，收到对方的 FIN 请求后，发送 ACK 响应，会处于 time_wait 状态；

![img](http://pcc.huitogo.club/83026e312ec9b72105a7a3850e9ebd74)



持续高并发场景tw情况

持续的高并发场景：一部分 TIME_WAIT 连接被回收，但新的 TIME_WAIT 连接产生；一些极端情况下，会出现大量的 TIME_WAIT 连接。



Tw过多产生问题？

Nginx 作为反向代理时，大量的短链接，可能导致 Nginx 上的 TCP 连接处于 time_wait 状态：

- 每一个 time_wait 状态，都会占用一个「本地端口」，上限为 65535(16 bit，2 Byte)；

- 当大量的连接处于 time_wait 时，新建立 TCP 连接会出错




查看tcp链接状态： netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'



##### 3.9 nginx代理中的时间问题

![img](http://pcc.huitogo.club/04e9f894d219c2aa67aabedf3a98f633)

- request_time：从接收用户请求的第一个字节到发送完响应数据的时间

- upstream_connect_time：nginx跟后端建立连接的时间，其中包含连接握手(ssl)的时间。

- upstream_response_time：Nginx与后端建立连接到传输完数据连接断开为止的时间

- upstream_header_time：从上游服务器接收响应头的时间，单位为秒




总结

1. 排查请求链路耗时情况，需要了解各个时间含义，建立链接超时、数据处理超时，返回超时

   上游服务执行耗时 = $upstream_header_time - $upstream_connect_time

   数据响应到客户端耗时 = $request_time - $upstream_response_time

2. 有些超时在nginx排队，没有建立链接，就要排查nginx性能原因



#### 4. 生产监控工具

**JavaMelody监控利器**

1. 可以界面化查看,Java内存和Java CPU使用情况，实时http请求，sql统计，和http请求等，方便对应用程序实际运行情况进行衡量和统计;

2. 另一方面，JavaMelody 开销非常低，可以在QA中持续启用，如果在 QA 中没有出现问题，也可以在生产环境中持续启用。




#### 5. 问题排查思路总结

第一步： 确认问题现象,影响范围， 可能涉及的外部服务（配合）, 是否需要挂载维护界面

第二步： 通过grafana监控页面， 确认服务节点、服务器、依赖组件服务是否正常

第三步： 通过javaMelody监控页面查看， 处理http线程阻塞（第三方接口），是否存储大量慢sql，线程是否用满

第四步： 查看nginx服务请求处理情况， 查看服务tw情况

第五步： 日志平台查看异常日志；skywalking查看超时异常情况；到k8s组件节点查看日志情况

第六步： 给出解决方案，通过测试工具、压测命令验证问题或猜测，完成问题修复