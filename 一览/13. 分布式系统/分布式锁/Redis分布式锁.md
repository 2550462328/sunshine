#### 1. Redis 分布式锁

这个分布式锁有 3 个重要的考量点：

- 互斥（只能有一个客户端获取锁）
- 不能死锁
- 容错（只要大部分 Redis 节点创建了这把锁就可以）



**加锁**

第一个最普通的实现方式，就是在 Redis 里使用 `SET key value [EX seconds] [PX milliseconds] NX` 创建一个 key，这样就算加锁。其中：

- `NX`：表示只有 `key` 不存在的时候才会设置成功，如果此时 redis 中存在这个 `key`，那么设置失败，返回 `nil`。
- `EX seconds`：设置 `key` 的过期时间，精确到秒级。意思是 `seconds` 秒后锁自动释放，别人创建的时候如果发现已经有了就不能加锁了。
- `PX milliseconds`：同样是设置 `key` 的过期时间，精确到毫秒级。



比如执行以下命令：

```r
SET resource_name my_random_value PX 30000 NX
```



**解锁**

释放锁就是删除 key ，但是一般可以用 `lua` 脚本删除，判断 value 一样才删除：

```lua
-- 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```



**为啥要用 `random_value` 随机值呢？**

因为如果某个客户端获取到了锁，但是阻塞了很长时间才执行完，比如说超过了 30s，此时可能已经自动释放锁了，此时可能别的客户端已经获取到了这个锁，要是你这个时候直接删除 key 的话会有问题，所以得用随机值加上面的 `lua` 脚本来释放锁。



#### 2. 使用Redission实现分布式锁

Redission封装了锁的实现，其继承了java.util.concurrent.locks.Lock的接口，让我们像操作我们的本地Lock一样去操作Redission的Lock，下面介绍一下其如何实现分布式锁。

![img](http://pcc.huitogo.club/fc811d06e58999fcd3427b491198688d)



Redission不仅提供了Java自带的一些方法(lock,tryLock)，还提供了异步加锁，对于异步编程更加方便。



##### 2.1 tryLock

加锁流程如下：

1. 尝试加锁：首先会尝试进行加锁，由于保证操作是原子性，那么就只能使用lua脚本，相关的lua脚本如下：

![img](http://pcc.huitogo.club/af151cdadbd6b64702f461aa42a69236)



可以看见他并没有使用我们的sexNx来进行操作，而是使用的hash结构，我们的每一个需要锁定的资源都可以看做是一个HashMap，锁定资源的节点信息是Key,锁定次数是value。通过这种方式可以很好的实现可重入的效果，只需要对value进行加1操作，就能进行可重入锁。当然这里也可以用之前我们说的本地计数进行优化。

2. 如果尝试加锁失败，判断是否超时，如果超时则返回false。

3. 如果加锁失败之后，没有超时，那么需要在名字为redisson_lock__channel+lockName的channel上进行订阅，用于订阅解锁消息，然后一直阻塞直到超时，或者有解锁消息。

4. 重试步骤1，2，3，直到最后获取到锁，或者某一步获取锁超时。



##### 2.2 unlock

解锁也是通过lua脚本实现的，如果是可重入锁，只是减1。如果是非加锁线程解锁，那么解锁失败。

![img](http://pcc.huitogo.club/175901357a3910e55b83ec776d3ffd82)



Redission还有公平锁的实现，对于公平锁其利用了list结构和hashset结构分别用来保存我们排队的节点，和我们节点的过期时间，用这两个数据结构帮助我们实现公平锁。



#### 3. RedLock 算法

**为什么会出现RedLock算法，或者普通的Redis锁有什么诟病？**

普通的Redis锁只作用在一个Redis节点上，如果通过sentinel保证高可用，如果master节点由于某些原因发生了主从切换，那么就会出现锁丢失的情况：

1. 客户端1在Redis的master节点上拿到了锁
2. Master宕机了，存储锁的key还没有来得及同步到Slave上
3. master故障，发生故障转移，slave节点升级为master节点
4. 客户端2从新的Master获取到了对应同一个资源的锁　
5. 于是，客户端1和客户端2同时持有了同一个资源的锁。



**锁的安全性被打破了**。针对这个问题。Redis作者antirez提出了RedLock算法来解决这个问题

这个场景是假设有一个 Redis cluster，有 5 个 Redis master 实例。然后执行如下步骤获取一把锁：

1. 获取当前时间戳，单位是毫秒；
2. 跟上面类似，轮流尝试在每个 master 节点上创建锁，超时时间较短，一般就几十毫秒（客户端为了获取锁而使用的超时时间比自动释放锁的总时间要小。例如，如果自动释放时间是 10 秒，那么超时时间可能在 `5~50` 毫秒范围内）；
3. 尝试在**大多数节点**上建立一个锁，比如 5 个节点就要求是 3 个节点 `n / 2 + 1` ；
4. 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；
5. 要是锁建立失败了，那么就依次之前建立过的锁删除；
6. 只要别人建立了一把分布式锁，你就得**不断轮询去尝试获取锁**。

![redis-redlock](https://doocs.gitee.io/advanced-java/docs/distributed-system/images/redis-redlock.png)

虽然说RedLock算法可以解决单点Redis分布式锁的安全性问题，但如果集群中有节点发生崩溃重启，还是会锁的安全性有影响的。具体出现问题的场景如下：

1. 假设一共有5个Redis节点：A, B, C, D, E。设想发生了如下的事件序列：
2. 客户端1成功锁住了A, B, C，获取锁成功（但D和E没有锁住）
3. 节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了
4. 节点C重启后，客户端2锁住了C, D, E，获取锁成功



这样，客户端1和客户端2同时获得了锁（针对同一资源）。针对这样场景，解决方式也很简单，也就是让Redis崩溃后延迟重启，并且这个延迟时间大于锁的过期时间就好。这样等节点重启后，所有节点上的锁都已经失效了。也不存在以上出现2个客户端获取同一个资源的情况了。　