寻址算法有：

- hash 算法（大量缓存重建）
- 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）
- Redis cluster 的 hash slot 算法



#### 1. hash 算法

来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致**大部分的请求过来，全部无法拿到有效的缓存**，导致大量的流量涌入数据库。



#### 2. 一致性 hash 算法

在了解什么是一致性Hash算法之前，先了解一下为什么需要hash算法

在redis中数据过多的时候我们可能会考虑分表分库，比如现在有2000万条数据，用4个redis库去存储，每个redis库存储500万条，并且每个redis库坐主从复制，架构类似下图

![img](http://pcc.huitogo.club/75847246160fd9d6d5a00c9b7245f35e)



这时候假设规则是随机的，一个redis的key可能存储在4个服务器中的任一台，因此我们需要进行1、2、3、4，4次查询才能够查询到（也就是遍历了所有的Redis服务器），这显然不是我们想要的结果，这个时候有人会说随机的规则不行，可以使用类似于数据库中的分库分表规则：按照Hash值、取模、按照类别、按照某一个字段值等等常见的规则，下面假设使用这些规则后。

类似架构图如下

![img](http://pcc.huitogo.club/6018622f576a3f46d09000c1b91aee5b)



上图中，假设我们查找的是”a.png”，由于有4台服务器（排除从库），因此公式为hash(a.png) % 4 = 2 ，可知定位到了第2号服务器，这样的话就不会遍历所有的服务器，大大提升了性能！

但是！在遇到新增或者减少redis服务器的情况下，所有的key计算后的值就无效了，意味着所有缓存的位置都要发生改变！换句话说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端数据库请求数据，也就会**造成缓存雪崩**。

综合以上，在对hash算法的优化上引入了**一致性hash算法**

一致性Hash算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性Hash算法是对2^32取模，什么意思呢？简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个**哈希环**如下： 

![img](http://pcc.huitogo.club/e4cbd82193c5719f4401b8de97eaf909)



下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用IP地址哈希后在环空间的位置如下： 

![img](http://pcc.huitogo.club/7f5ebf6d9ad83c237d5ecfd2a4e36d55)



接下来将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器！

例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下： 

![img](http://pcc.huitogo.club/75893a10c46fa9d361bf8d4c0d601c51)



根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。

在一致性hash算法下，假设NodeC不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，**在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器**（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。同样的**如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器**（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。

**综上所述，一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。**



**一致性hash算法会带来哪些问题呢？**

**数据倾斜问题**

一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下： 

![img](http://pcc.huitogo.club/3ec067cd8feccd842545915b3bc519b3)

此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。



怎么解决呢？

一致性Hash算法引入了**虚拟节点机制**，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。

例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点： 

![img](http://pcc.huitogo.club/954d78701c644eaf457293968dada365)



同时数据定位算法不变，只是多了一步**虚拟节点到实际节点的映射**，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，**通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布**。



#### 3. Redis cluster 的 hash slot 算法

Redis cluster 有固定的 `16384` 个 hash slot，对每个 `key` 计算 `CRC16` 值，然后对 `16384` 取模，可以获取 key 对应的 hash slot。

Redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 `hash tag` 来实现。

任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。